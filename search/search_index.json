{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Azure ML Cheat Sheet Basics Workspace Instantiate Workspace object used to connect to your AML assets. from azureml.core import Workspace ws = Workspace ( subscription_id = \"<subscription_id>\" , resource_group = \"<resource_group>\" , workspace_name = \"<workspace_name>\" , ) For convenience store your credentials in a config.json : from azureml.core import Workspace ws . write_config () # write config.json file with your AML credentials ws = Workspace . from_config () # read your aml credentials from config.json and instantiate # Workspace object VS Code snippet Workspaces are a foundational object used throughout AML and are used in the constructors of many other classes. In the following examples we frequently omit the workspace object instantiation and simply refer to ws . See the workspaces page for more ways to instantiate a workspace. Datastore Each workspace comes with a default datastore. ds = ws . get_default_datastore () Any datastore that is registered to workspace can be accessed by name. from azureml.core import Datastore ds = Datastore . get ( ws , \"<name-of-registered-datastore>\" ) To register an Azure Blob container via a SAS token: ds = Datastore . register_azure_blob_container ( workspace = ws , datastore_name = \"<datastore-name>\" , container_name = \"<container-name>\" , account_name = \"<account-name>\" , sas_token = \"<sas-token>\" , ) VS Code snippet For more authentication options and for different underlying storage see the AML documentation on Datastores . Compute Targets Compute targets are an AML abstraction around the concept of a compute resource. This can range from your local machine to an (auto-scaling) cluster of Azure VMs. To use an existing compute target: from azureml.core import ComputeTarget compute_target = ComputeTarget ( workspace = ws , name = \"<compute-name>\" ) For example, to create a new cluster of between 0 and 4 \"Standard_NC24rs_v3\" VMs, from azureml.core import ComputeTarget from azureml.core.compute import AmlCompute compute_config = AmlCompute . provisioning_configuration ( vm_size = \"Standard_NC24rs_v3\" , min_nodes = 0 , max_nodes = 4 , ) compute_target = ComputeTarget . create ( ws , \"<compute-name>\" , compute_config ) compute_target . wait_for_completion ( show_output = True ) See the Compute Targets page for more examples. Running Scripts in AML To run code in AML you need to: Configure : Configuration includes specifying the code to run, the compute target to run on and the Python environment to run in. Submit : Create or reuse an AML Experiment and submit the run. ScriptRunConfig A typical directory may have the following structure: source_directory/ script.py # entry point to your code module1.py # modules called by script.py ... ScriptRunConfig: Basic from azureml.core import ScriptRunConfig config = ScriptRunConfig ( source_directory = '<path/to/source_directory>' , # relative paths okay script = 'script.py' , ) ScriptRunConfig:Command line arguments Moreover, script.py may be set up to accept command line arguments python script.py --argument 42 --another_argument 73 In that case we pass the arguments list to config : from azureml.core import ScriptRunConfig config = ScriptRunConfig ( source_directory = '<path/to/source_directory>' , # relative paths okay script = 'script.py' , arguments = [ 'argument' , 42 , 'another_argument' , 73 , ], ) ScriptRunConfig: ComputeTarget By default this configuration will run on local compute. To use AML compute target specify in the run_config attribute: from azureml.core import ComputeTarget compute_target = ComputeTarget ( workspace = ws , name = \"<compute-name>\" ) config . run_config . target = target # of type azureml.core.ComputeTarget See Compute Targets for creating and accessing AML ComputeTargets. ScriptRunConfig: Environment If your script requires a specific Python environment to run pass specify in the run_config attribute: from azureml.core import Environment env = Environment ( ws , '<environment-name>' ) config . run_config . environment = env # of type azureml.core.Environment See Environment for creating and accessing AML Environments. Experiments An experiment is used as an organizational principle, storing run history and tracking metrics. Get or create an experiment: from azureml.core import Experiment exp = Experiment ( ws , \"<experiment-name>\" ) Use experiments to submit run configurations to AML. run = exp . submit ( config ) Environments Environment We can use a Conda/pip to define AML environments. Conda (env.yml) Generate a Conda env.yml : first activate your Conda environment and then run: conda env export > env.yml pip (requirements.txt) Generate a pip requrements.txt file: first activate your pip environment and then run: pip freeze > requirements.txt Create the AML environment Conda from azureml.core import Environment my_env = Environment . from_conda_specification ( name = '<environment-name>' , file_path = '<path-to-env.yml>' , ) pip from azureml.core import Environment my_env = Environment . from_pip_specification ( name = '<environment-name>' , file_path = '<path-to-requirements.txt>' , ) To register this environment with the workspace my_env . register ( ws ) To view all environments registered to a workspace from azureml.core import Environment registered_environments = Environment . list ( ws ) Logging Logging metrics To log metrics in your running script add the following: from azureml.core import Run run = Run . get_context () run . log ( \"metric-name\" , metric_value ) Viewing metrics with the Python SDK Viewing metrics in a run metrics = run . get_metrics () # metrics is of type Dict[str, List[float]] mapping mertic names # to a list of the values for that metric in the given run. metrics . get ( \"metric-name\" ) # list of metrics in the order they were recorded To view all recorded values for a given metric my-metric in a given experiment my-experiment : experiments = ws . experiments # of type Dict[str, Experiment] mapping experiment names the # corresponding Experiment exp = experiments [ 'my-experiment' ] for run in exp . get_runs (): metrics = run . get_metrics () my_metric = metrics . get ( 'my-metric' ) if my_metric : print ( my_metric )","title":"Cheatsheet"},{"location":"#azure-ml-cheat-sheet","text":"","title":"Azure ML Cheat Sheet"},{"location":"#basics","text":"","title":"Basics"},{"location":"#workspace","text":"Instantiate Workspace object used to connect to your AML assets. from azureml.core import Workspace ws = Workspace ( subscription_id = \"<subscription_id>\" , resource_group = \"<resource_group>\" , workspace_name = \"<workspace_name>\" , ) For convenience store your credentials in a config.json : from azureml.core import Workspace ws . write_config () # write config.json file with your AML credentials ws = Workspace . from_config () # read your aml credentials from config.json and instantiate # Workspace object VS Code snippet Workspaces are a foundational object used throughout AML and are used in the constructors of many other classes. In the following examples we frequently omit the workspace object instantiation and simply refer to ws . See the workspaces page for more ways to instantiate a workspace.","title":"Workspace"},{"location":"#datastore","text":"Each workspace comes with a default datastore. ds = ws . get_default_datastore () Any datastore that is registered to workspace can be accessed by name. from azureml.core import Datastore ds = Datastore . get ( ws , \"<name-of-registered-datastore>\" ) To register an Azure Blob container via a SAS token: ds = Datastore . register_azure_blob_container ( workspace = ws , datastore_name = \"<datastore-name>\" , container_name = \"<container-name>\" , account_name = \"<account-name>\" , sas_token = \"<sas-token>\" , ) VS Code snippet For more authentication options and for different underlying storage see the AML documentation on Datastores .","title":"Datastore"},{"location":"#compute-targets","text":"Compute targets are an AML abstraction around the concept of a compute resource. This can range from your local machine to an (auto-scaling) cluster of Azure VMs. To use an existing compute target: from azureml.core import ComputeTarget compute_target = ComputeTarget ( workspace = ws , name = \"<compute-name>\" ) For example, to create a new cluster of between 0 and 4 \"Standard_NC24rs_v3\" VMs, from azureml.core import ComputeTarget from azureml.core.compute import AmlCompute compute_config = AmlCompute . provisioning_configuration ( vm_size = \"Standard_NC24rs_v3\" , min_nodes = 0 , max_nodes = 4 , ) compute_target = ComputeTarget . create ( ws , \"<compute-name>\" , compute_config ) compute_target . wait_for_completion ( show_output = True ) See the Compute Targets page for more examples.","title":"Compute Targets"},{"location":"#running-scripts-in-aml","text":"To run code in AML you need to: Configure : Configuration includes specifying the code to run, the compute target to run on and the Python environment to run in. Submit : Create or reuse an AML Experiment and submit the run.","title":"Running Scripts in AML"},{"location":"#scriptrunconfig","text":"A typical directory may have the following structure: source_directory/ script.py # entry point to your code module1.py # modules called by script.py ... ScriptRunConfig: Basic from azureml.core import ScriptRunConfig config = ScriptRunConfig ( source_directory = '<path/to/source_directory>' , # relative paths okay script = 'script.py' , ) ScriptRunConfig:Command line arguments Moreover, script.py may be set up to accept command line arguments python script.py --argument 42 --another_argument 73 In that case we pass the arguments list to config : from azureml.core import ScriptRunConfig config = ScriptRunConfig ( source_directory = '<path/to/source_directory>' , # relative paths okay script = 'script.py' , arguments = [ 'argument' , 42 , 'another_argument' , 73 , ], ) ScriptRunConfig: ComputeTarget By default this configuration will run on local compute. To use AML compute target specify in the run_config attribute: from azureml.core import ComputeTarget compute_target = ComputeTarget ( workspace = ws , name = \"<compute-name>\" ) config . run_config . target = target # of type azureml.core.ComputeTarget See Compute Targets for creating and accessing AML ComputeTargets. ScriptRunConfig: Environment If your script requires a specific Python environment to run pass specify in the run_config attribute: from azureml.core import Environment env = Environment ( ws , '<environment-name>' ) config . run_config . environment = env # of type azureml.core.Environment See Environment for creating and accessing AML Environments.","title":"ScriptRunConfig"},{"location":"#experiments","text":"An experiment is used as an organizational principle, storing run history and tracking metrics. Get or create an experiment: from azureml.core import Experiment exp = Experiment ( ws , \"<experiment-name>\" ) Use experiments to submit run configurations to AML. run = exp . submit ( config )","title":"Experiments"},{"location":"#environments","text":"","title":"Environments"},{"location":"#environment","text":"We can use a Conda/pip to define AML environments. Conda (env.yml) Generate a Conda env.yml : first activate your Conda environment and then run: conda env export > env.yml pip (requirements.txt) Generate a pip requrements.txt file: first activate your pip environment and then run: pip freeze > requirements.txt Create the AML environment Conda from azureml.core import Environment my_env = Environment . from_conda_specification ( name = '<environment-name>' , file_path = '<path-to-env.yml>' , ) pip from azureml.core import Environment my_env = Environment . from_pip_specification ( name = '<environment-name>' , file_path = '<path-to-requirements.txt>' , ) To register this environment with the workspace my_env . register ( ws ) To view all environments registered to a workspace from azureml.core import Environment registered_environments = Environment . list ( ws )","title":"Environment"},{"location":"#logging","text":"","title":"Logging"},{"location":"#logging-metrics","text":"To log metrics in your running script add the following: from azureml.core import Run run = Run . get_context () run . log ( \"metric-name\" , metric_value )","title":"Logging metrics"},{"location":"#viewing-metrics-with-the-python-sdk","text":"Viewing metrics in a run metrics = run . get_metrics () # metrics is of type Dict[str, List[float]] mapping mertic names # to a list of the values for that metric in the given run. metrics . get ( \"metric-name\" ) # list of metrics in the order they were recorded To view all recorded values for a given metric my-metric in a given experiment my-experiment : experiments = ws . experiments # of type Dict[str, Experiment] mapping experiment names the # corresponding Experiment exp = experiments [ 'my-experiment' ] for run in exp . get_runs (): metrics = run . get_metrics () my_metric = metrics . get ( 'my-metric' ) if my_metric : print ( my_metric )","title":"Viewing metrics with the Python SDK"},{"location":"templates/","text":"Templates Introduction Cookiecutter is a simple command-line tool that allows you to quickly create new projects from pre-defined templates. Let's see it in action! First go ahead and get cookiecutter using your environment manager of choice, for example: pip install cookiecutter Then give this repo a home cd ~/repos # or wherever your repos call home :-) git clone <this-repo> To create a new project from the ScriptRunConfig template for example, simply run cookiecutter path/to/cheatsheet/repo/templates/ScriptRunConfig See ScriptRunConfig for more details for this template. Templates ScriptRunConfig: Create a project to run a script in AML making use of the ScriptRunConfig class. This template is well suited for smaller projects and is especially handy for testing. ScriptRunConfig Cookiecutter template for setting up an AML ScriptRunConfig used to run your script in Azure. Usage Run the cookiecutter command cookiecutter <path/to/cookiecutter/templates>/ScriptRunConfig to create a new ScriptRunConfig project. Note. Install with pip install cookiecutter (see cookiecutter docs for more installation options) You will be prompted for the following: directory_name : The desired name of the directory (default: \"aml-src-script\") script_name : The name of the python script to be run in Azure (default: \"script\") subscription_id : Your Azure Subscription ID resource_group : Your Azure resource group name workspace_name : Your Azure ML workspace name compute_target_name : The name of the Azure ML compute target to run the script on (default: \"local\", will run on your box) Cookiecutter creates a new project with the following layout. {directory_name}/ {script_name}.py # the script you want to run in the cloud run.py # wraps your script in ScriptRunConfig to send to Azure config.json # your Azure ML metadata readme.md # this readme file! See ScriptRunConfig for more options and details on configuring runs.","title":"Templates"},{"location":"templates/#templates","text":"","title":"Templates"},{"location":"templates/#introduction","text":"Cookiecutter is a simple command-line tool that allows you to quickly create new projects from pre-defined templates. Let's see it in action! First go ahead and get cookiecutter using your environment manager of choice, for example: pip install cookiecutter Then give this repo a home cd ~/repos # or wherever your repos call home :-) git clone <this-repo> To create a new project from the ScriptRunConfig template for example, simply run cookiecutter path/to/cheatsheet/repo/templates/ScriptRunConfig See ScriptRunConfig for more details for this template.","title":"Introduction"},{"location":"templates/#templates_1","text":"ScriptRunConfig: Create a project to run a script in AML making use of the ScriptRunConfig class. This template is well suited for smaller projects and is especially handy for testing.","title":"Templates"},{"location":"templates/#scriptrunconfig","text":"Cookiecutter template for setting up an AML ScriptRunConfig used to run your script in Azure.","title":"ScriptRunConfig"},{"location":"templates/#usage","text":"Run the cookiecutter command cookiecutter <path/to/cookiecutter/templates>/ScriptRunConfig to create a new ScriptRunConfig project. Note. Install with pip install cookiecutter (see cookiecutter docs for more installation options) You will be prompted for the following: directory_name : The desired name of the directory (default: \"aml-src-script\") script_name : The name of the python script to be run in Azure (default: \"script\") subscription_id : Your Azure Subscription ID resource_group : Your Azure resource group name workspace_name : Your Azure ML workspace name compute_target_name : The name of the Azure ML compute target to run the script on (default: \"local\", will run on your box) Cookiecutter creates a new project with the following layout. {directory_name}/ {script_name}.py # the script you want to run in the cloud run.py # wraps your script in ScriptRunConfig to send to Azure config.json # your Azure ML metadata readme.md # this readme file! See ScriptRunConfig for more options and details on configuring runs.","title":"Usage"},{"location":"more/compute-targets/","text":"Compute Targets The following will first attempt to retrieve an existing compute target by its name. If the compute does not exist it will create the cluster. from azureml.core import ComputeTarget from azureml.core.compute import AmlCompute from azureml.core.compute_target import ComputeTargetException compute_name = \"<compute-name>\" try : compute_target = ComputeTarget ( workspace = ws , name = compute_name ) print ( f 'Found existing compute target: { compute_name } .' ) except ComputeTargetException : print ( 'Creating a new compute target...' ) compute_target = ComputeTarget . create ( ws , compute_name , compute_config ) compute_target . wait_for_completion ( show_output = True )","title":"Compute Targets"},{"location":"more/compute-targets/#compute-targets","text":"The following will first attempt to retrieve an existing compute target by its name. If the compute does not exist it will create the cluster. from azureml.core import ComputeTarget from azureml.core.compute import AmlCompute from azureml.core.compute_target import ComputeTargetException compute_name = \"<compute-name>\" try : compute_target = ComputeTarget ( workspace = ws , name = compute_name ) print ( f 'Found existing compute target: { compute_name } .' ) except ComputeTargetException : print ( 'Creating a new compute target...' ) compute_target = ComputeTarget . create ( ws , compute_name , compute_config ) compute_target . wait_for_completion ( show_output = True )","title":"Compute Targets"},{"location":"more/datastore/","text":"","title":"Datastore"},{"location":"more/environment/","text":"Environment From conda/pip files We can use a Conda/pip to define AML environments. Conda (env.yml) # env.yml name: my-env channels: - defaults - conda-forge dependencies: - numpy - pandas - scipy - scikit-learn - pip - python=3.6 - jupyter - ipykernel - pip: - azureml-sdk==1.8.0 - torch - transformers==2.11.0 pip (requirements.txt) # requirement.txt azureml-dataprep==1.8.3 azureml-sdk==1.8.0 flake8==3.7.9 numpy==1.18.5 pycodestyle==2.5.0 torch==1.5.1 tqdm==4.48.0 transformers==2.11.0 to create and register an AML environment that can be cached, versioned and reused between different experiments, runs and compute targets. Create the AML environment Conda from azureml.core import Environment my_env = Environment . from_conda_specification ( name = '<environment-name>' , file_path = '<path-to-env.yml>' , ) pip from azureml.core import Environment my_env = Environment . from_pip_specification ( name = '<environment-name>' , file_path = '<path-to-requirements.txt>' , ) To register this environment with the workspace my_env . register ( ws ) To view all environments registered to a workspace from azureml.core import Environment registered_environments = Environment . list ( ws ) Specifying dependencies TODO","title":"Environment"},{"location":"more/environment/#environment","text":"","title":"Environment"},{"location":"more/environment/#from-condapip-files","text":"We can use a Conda/pip to define AML environments. Conda (env.yml) # env.yml name: my-env channels: - defaults - conda-forge dependencies: - numpy - pandas - scipy - scikit-learn - pip - python=3.6 - jupyter - ipykernel - pip: - azureml-sdk==1.8.0 - torch - transformers==2.11.0 pip (requirements.txt) # requirement.txt azureml-dataprep==1.8.3 azureml-sdk==1.8.0 flake8==3.7.9 numpy==1.18.5 pycodestyle==2.5.0 torch==1.5.1 tqdm==4.48.0 transformers==2.11.0 to create and register an AML environment that can be cached, versioned and reused between different experiments, runs and compute targets. Create the AML environment Conda from azureml.core import Environment my_env = Environment . from_conda_specification ( name = '<environment-name>' , file_path = '<path-to-env.yml>' , ) pip from azureml.core import Environment my_env = Environment . from_pip_specification ( name = '<environment-name>' , file_path = '<path-to-requirements.txt>' , ) To register this environment with the workspace my_env . register ( ws ) To view all environments registered to a workspace from azureml.core import Environment registered_environments = Environment . list ( ws )","title":"From conda/pip files"},{"location":"more/environment/#specifying-dependencies","text":"TODO","title":"Specifying dependencies"},{"location":"more/workspace/","text":"Workspace Instantiate workspace. from azureml.core import Workspace ws = Workspace . from_config () This examples reads the workspace from a config.json file, the contents of which are of the form { \"subscription_id\" : <subscription-id> , \"resource_group\" : <resource-group> , \"workspace_name\" : <workspace-name> } Alternatively you can provide these values directly: from azureml.core import Workspace ws = Workspace . get ( name = \"<workspace-name>\" , subscription_id = \"<subscription-id>\" , resource_group = \"<resource-group>\" , )","title":"Workspace"},{"location":"more/workspace/#workspace","text":"Instantiate workspace. from azureml.core import Workspace ws = Workspace . from_config () This examples reads the workspace from a config.json file, the contents of which are of the form { \"subscription_id\" : <subscription-id> , \"resource_group\" : <resource-group> , \"workspace_name\" : <workspace-name> } Alternatively you can provide these values directly: from azureml.core import Workspace ws = Workspace . get ( name = \"<workspace-name>\" , subscription_id = \"<subscription-id>\" , resource_group = \"<resource-group>\" , )","title":"Workspace"},{"location":"vs-code-snippets/snippets/","text":"VS Code Snippets We have compiled a collection of VS code snippets designed to make it easy to work with Azure ML. To add these snippets to your VS Code: ctrl+shift+p > Type \"Configure user snippets\" > Select python.json . All of these snippets are available here: python.json Basic core imports \"Basic core imports\" : { \"prefix\" : \"workspace-imports-creation\" , \"body\" : [ \"from azureml.core import Workspace, Experiment, Run, RunConfiguration, ComputeTarget$1\" , \"$0\" ], \"description\" : \"Import essential packages\" } Pipeline imports \"Pipeline Imports\" : { \"prefix\" : \"pipeline-imports\" , \"body\" : [ \"from azureml.pipeline.core import Pipeline, PipelineData, PipelineParameter\" , \"from azureml.pipeline.steps import PythonScriptStep$1\" , \"$0\" ], \"description\" : \"Basic imports for pipeline\" } Create AML Workspace from config \"Create AML Workspace from config\" : { \"prefix\" : [ \"workspace-quick\" , \"fromconfig\" , \"from-config\" ], \"body\" : [ \"ws = Workspace.from_config()\" , \"$0\" ], \"description\" : \"Default workspace creation\" } Create AML Workspace from config and auth \"Create AML Workspace from config and auth\" : { \"prefix\" : \"workspace-from-config-auth\" , \"body\" : [ \"from azureml.core.authentication import InteractiveLoginAuthentication\" , \"config = {'subscription_id':'$1',\" , \"'resource_group':'$2',\" , \"'workspace_name' :'$3'}\" , \"auth = InteractiveLoginAuthentication()\" , \"ws = Workspace(**config,auth = auth)\" , \"$0\" ], \"description\" : \"Create workspace from config and auth\" } Register Azure Blob Container From SAS \"Register Azure Blob Container From SAS\" : { \"prefix\" : [ \"datastore-register-blob-sas\" , \"reg-blob-sas\" ], \"body\" : [ \"ds = Datastore.register_azure_blob_container(\" \" workspace='$1',\" \" datastore_name='$2',\" , \" container_name='$3',\" , \" account_name='$4',\" , \" sas_token='$5',\" , \")\" \"$0\" ], \"description\" : \"Register Azure Blob container to workspace via SAS\" } Create Compute Cluster with SSH \"Create Compute Cluster with SSH\" : { \"prefix\" : [ \"create-compute-cluster-ssh\" ], \"body\" : [ \"from azureml.core.compute import AmlCompute\" , \"from azureml.core.compute_target import ComputeTargetException\" , \"ssh_public_key = '$1'\" , \"compute_config = AmlCompute.provisioning_configuration(vm_size='$4',min_nodes=$5, max_nodes=$6,admin_username='$7',admin_user_ssh_key=ssh_public_key,vm_priority='${8|lowpriority,dedicated|}',remote_login_port_public_access='Enabled')\" , \"cluster$0 = ComputeTarget.create(workspace=$9, name='$10', compute_config)\" ], \"description\" : \"Create compute cluster with SSH enabled\" }","title":"VS Code Snippets"},{"location":"vs-code-snippets/snippets/#vs-code-snippets","text":"We have compiled a collection of VS code snippets designed to make it easy to work with Azure ML. To add these snippets to your VS Code: ctrl+shift+p > Type \"Configure user snippets\" > Select python.json . All of these snippets are available here: python.json","title":"VS Code Snippets"},{"location":"vs-code-snippets/snippets/#basic-core-imports","text":"\"Basic core imports\" : { \"prefix\" : \"workspace-imports-creation\" , \"body\" : [ \"from azureml.core import Workspace, Experiment, Run, RunConfiguration, ComputeTarget$1\" , \"$0\" ], \"description\" : \"Import essential packages\" }","title":"Basic core imports"},{"location":"vs-code-snippets/snippets/#pipeline-imports","text":"\"Pipeline Imports\" : { \"prefix\" : \"pipeline-imports\" , \"body\" : [ \"from azureml.pipeline.core import Pipeline, PipelineData, PipelineParameter\" , \"from azureml.pipeline.steps import PythonScriptStep$1\" , \"$0\" ], \"description\" : \"Basic imports for pipeline\" }","title":"Pipeline imports"},{"location":"vs-code-snippets/snippets/#create-aml-workspace-from-config","text":"\"Create AML Workspace from config\" : { \"prefix\" : [ \"workspace-quick\" , \"fromconfig\" , \"from-config\" ], \"body\" : [ \"ws = Workspace.from_config()\" , \"$0\" ], \"description\" : \"Default workspace creation\" }","title":"Create AML Workspace from config"},{"location":"vs-code-snippets/snippets/#create-aml-workspace-from-config-and-auth","text":"\"Create AML Workspace from config and auth\" : { \"prefix\" : \"workspace-from-config-auth\" , \"body\" : [ \"from azureml.core.authentication import InteractiveLoginAuthentication\" , \"config = {'subscription_id':'$1',\" , \"'resource_group':'$2',\" , \"'workspace_name' :'$3'}\" , \"auth = InteractiveLoginAuthentication()\" , \"ws = Workspace(**config,auth = auth)\" , \"$0\" ], \"description\" : \"Create workspace from config and auth\" }","title":"Create AML Workspace from config and auth"},{"location":"vs-code-snippets/snippets/#register-azure-blob-container-from-sas","text":"\"Register Azure Blob Container From SAS\" : { \"prefix\" : [ \"datastore-register-blob-sas\" , \"reg-blob-sas\" ], \"body\" : [ \"ds = Datastore.register_azure_blob_container(\" \" workspace='$1',\" \" datastore_name='$2',\" , \" container_name='$3',\" , \" account_name='$4',\" , \" sas_token='$5',\" , \")\" \"$0\" ], \"description\" : \"Register Azure Blob container to workspace via SAS\" }","title":"Register Azure Blob Container From SAS"},{"location":"vs-code-snippets/snippets/#create-compute-cluster-with-ssh","text":"\"Create Compute Cluster with SSH\" : { \"prefix\" : [ \"create-compute-cluster-ssh\" ], \"body\" : [ \"from azureml.core.compute import AmlCompute\" , \"from azureml.core.compute_target import ComputeTargetException\" , \"ssh_public_key = '$1'\" , \"compute_config = AmlCompute.provisioning_configuration(vm_size='$4',min_nodes=$5, max_nodes=$6,admin_username='$7',admin_user_ssh_key=ssh_public_key,vm_priority='${8|lowpriority,dedicated|}',remote_login_port_public_access='Enabled')\" , \"cluster$0 = ComputeTarget.create(workspace=$9, name='$10', compute_config)\" ], \"description\" : \"Create compute cluster with SSH enabled\" }","title":"Create Compute Cluster with SSH"}]}